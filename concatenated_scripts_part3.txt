# Concatenated Project Code - Part 3 of 3
# Generated: 2025-05-12 16:05:28
# Root Directory: /Users/gianmariatroiani/Documents/misophonia-companion-v3
================================================================================

################################################################################
# File: src/App.jsx
################################################################################

import './App.css'
import React, { useState, useEffect, useRef } from 'react';
import botAvatar from './assets/bot-avatar.png';
import userAvatar from './assets/user-avatar.png';
import TermsModal from './TermsModal';
import RagAssistant from './RagAssistant.jsx';


function NavBar({ setSection, section }) {
  return (
    <nav className="navbar">
      <button className={section === 'home' ? 'active' : ''} onClick={() => setSection('home')}>
        <span role="img" aria-label="home" style={{marginRight: 6}}>üè†</span> Home
      </button>
      <button className={section === 'chatbot' ? 'active' : ''} onClick={() => setSection('chatbot')}>
        <span role="img" aria-label="chat" style={{marginRight: 6}}>üí¨</span> Let's Talk
      </button>
      <button className={section === 'tools' ? 'active' : ''} onClick={() => setSection('tools')}>
        <span role="img" aria-label="tools" style={{marginRight: 6}}>üß∞</span> Therapeutic Tools
      </button>
      <button className={section === 'research' ? 'active' : ''} onClick={() => setSection('research')}>
        <span role="img" aria-label="research" style={{marginRight: 6}}>üî¨</span> Research Assistant
      </button>
    </nav>
  );
}

const AFFIRMATIONS = [
  "You are safe here.",
  "It's okay to take a break.",
  "Your feelings are valid.",
  "Breathe in calm, breathe out stress.",
  "You are not alone."
];
const SOUNDS = [
  { label: 'Rain', src: 'https://cdn.pixabay.com/audio/2022/07/26/audio_124bfae45e.mp3' },
  { label: 'Forest', src: 'https://cdn.pixabay.com/audio/2022/03/15/audio_115b9d7bfa.mp3' },
  { label: 'White Noise', src: 'https://cdn.pixabay.com/audio/2022/03/15/audio_115b9d7bfa.mp3' }
];

function AffirmationBanner() {
  const [idx] = useState(() => Math.floor(Math.random() * AFFIRMATIONS.length));
  return (
    <div style={{
      background: 'linear-gradient(90deg, #e0e7ef 60%, #f8f6ff 100%)',
      color: '#4b6073',
      borderRadius: '16px',
      margin: '0 0 1.1rem 0',
      padding: '0.7rem 1.2rem',
      fontSize: '1.12rem',
      fontWeight: 500,
      textAlign: 'center',
      boxShadow: '0 1px 6px 0 rgba(31, 38, 135, 0.04)',
      letterSpacing: '0.01em',
      opacity: 0.97
    }}>
      {AFFIRMATIONS[idx]}
    </div>
  );
}

function SoundscapePlayer() {
  const [playing, setPlaying] = useState(false);
  const [muted, setMuted] = useState(false);
  const [soundIdx, setSoundIdx] = useState(0);
  const audioRef = useRef(null);

  const handlePlayPause = () => {
    setPlaying(p => !p);
  };
  const handleMute = () => {
    setMuted(m => !m);
  };
  const handleSoundChange = (e) => {
    setSoundIdx(Number(e.target.value));
    setPlaying(false);
    setTimeout(() => setPlaying(true), 50);
  };

  useEffect(() => {
    if (!audioRef.current) return;
    audioRef.current.muted = muted;
    if (playing) {
      audioRef.current.play();
    } else {
      audioRef.current.pause();
    }
  }, [playing, muted, soundIdx]);

  return (
    <div style={{
      display: 'flex', alignItems: 'center', gap: '0.7rem',
      background: 'rgba(255,255,255,0.88)',
      borderRadius: '13px',
      padding: '0.25rem 0.8rem',
      marginBottom: '1.1rem',
      boxShadow: '0 1px 4px 0 rgba(31, 38, 135, 0.03)',
      fontSize: '1.01rem',
      maxWidth: 320
    }}>
      <span style={{color: '#b2d8d8', fontWeight: 700, fontSize: '1.1rem'}}>Soundscape:</span>
      <select value={soundIdx} onChange={handleSoundChange} style={{borderRadius: 7, border: '1px solid #e0e7ef', background: '#f8f6ff', color: '#4b6073', padding: '0.2rem 0.5rem'}}>
        {SOUNDS.map((s, i) => <option value={i} key={s.label}>{s.label}</option>)}
      </select>
      <button onClick={handlePlayPause} style={{border: 'none', background: 'none', cursor: 'pointer', color: playing ? '#81b0b0' : '#aaa', fontWeight: 700, fontSize: '1.05rem'}}>{playing ? 'Pause' : 'Play'}</button>
      <button onClick={handleMute} style={{border: 'none', background: 'none', cursor: 'pointer', color: muted ? '#aaa' : '#b2d8d8', fontWeight: 700, fontSize: '1.05rem'}}>{muted ? 'Unmute' : 'Mute'}</button>
      <audio ref={audioRef} src={SOUNDS[soundIdx].src} loop preload="auto" style={{display: 'none'}} />
    </div>
  );
}

function App() {
  const [section, setSection] = useState('home');
  const [termsAccepted, setTermsAccepted] = useState(localStorage.getItem('termsAccepted') === 'true');
  if (!termsAccepted) return <TermsModal onAccept={() => setTermsAccepted(true)} />;

  return (
    <>
      <div className="animated-bg">
        <div className="bubble bubble1"></div>
        <div className="bubble bubble2"></div>
        <div className="bubble bubble3"></div>
        <div className="bubble bubble4"></div>
        <div className="bubble bubble5"></div>
        <div className="bubble bubble6"></div>
        <div className="bubble bubble7"></div>
        <div className="bubble bubble8"></div>
      </div>

      {/* MAIN CONTENT BOX */}
      <div className="container">
        <AffirmationBanner />
        <SoundscapePlayer />
        <NavBar setSection={setSection} section={section} />
        {section === 'home' && (
          <div className="card">
            <main>
              <h1 className="title">Welcome to Misophonia Companion</h1>
              <p className="subtitle">A soothing space to manage triggers, support healing, and explore research‚Äîbuilt for both sufferers and professionals.</p>
            </main>
          </div>
        )}
        {section === 'chatbot' && <Chatbot />}
        {section === 'tools' && (
          <div className="card">
            <main>
              <h2>Therapeutic Tools</h2>
              <p>Coming soon: Sound therapy, coping strategies, and relaxation exercises.</p>
            </main>
          </div>
        )}
        {section === 'research' && <RagAssistant />}
      </div>

      {/* NEW: footer lives here, outside .container */}
      <div className="disclaimer-footer">
        Misophonia Companion is not a clinical tool or a substitute for
        professional psychological or medical treatment. It does not provide
        diagnosis, therapy, or crisis intervention. If you are experiencing a
        mental-health emergency, please contact a licensed provider or
        emergency services immediately.
      </div>
    </>
  );
}


function Chatbot() {
  const [messages, setMessages] = useState([
    { sender: 'bot', text: 'Hello! I am your Misophonia Companion. How can I support you today?' }
  ]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);

  async function handleSend(e) {
    e.preventDefault();
    if (!input.trim()) return;
    const userMsg = { sender: 'user', text: input };
    setMessages((msgs) => [...msgs, userMsg]);
    setLoading(true);
    setError(null);
    setInput('');
    try {
      const res = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          messages: [
            { role: 'system', content: 'You are a calm, supportive misophonia companion and research assistant.' },
            ...messages.map(m => ({ role: m.sender === 'user' ? 'user' : 'assistant', content: m.text })),
            { role: 'user', content: input }
          ]
        })
      });
      if (!res.ok) throw new Error('API error');
      const data = await res.json();
      setMessages((msgs) => [...msgs, { sender: 'bot', text: data.reply }]);
    } catch (err) {
      setMessages((msgs) => [...msgs, { sender: 'bot', text: 'Sorry, I could not connect to the assistant. Make sure the backend server and your API key are set up.' }]);
      setError('API error');
    } finally {
      setLoading(false);
    }
  }

  return (
    <main>
      <h2>Let's Talk</h2>
      <div className="chatbot-box">
        <div className="chat-messages">
          {messages.map((msg, idx) => (
            <div key={idx} className={msg.sender === 'bot' ? 'msg bot' : 'msg user'} style={{display: 'flex', alignItems: 'flex-end', justifyContent: msg.sender === 'user' ? 'flex-end' : 'flex-start'}}>
              {msg.sender === 'bot' && (
                <img
                  src={botAvatar}
                  alt="Bot"
                  className="chat-avatar"
                  onError={e => { e.target.onerror = null; e.target.src = 'https://ui-avatars.com/api/?name=Bot&background=b2d8d8&color=fff&rounded=true&size=64'; }}
                />
              )}
              <span className="bubble-content">{msg.text}</span>
              {msg.sender === 'user' && (
                <img
                  src={userAvatar}
                  alt="You"
                  className="chat-avatar"
                  onError={e => { e.target.onerror = null; e.target.src = 'https://ui-avatars.com/api/?name=You&background=ffdac1&color=3a3a3a&rounded=true&size=64'; }}
                />
              )}
            </div>
          ))}
          {loading && <div className="msg bot" style={{display: 'flex', alignItems: 'flex-end'}}><img src={botAvatar} alt="Bot" className="chat-avatar" /><span className="bubble-content">Thinking‚Ä¶</span></div>}
        </div>
        <form className="chat-input-row" onSubmit={handleSend}>
          <input
            type="text"
            value={input}
            onChange={e => setInput(e.target.value)}
            placeholder="Type your message..."
            className="chat-input"
            autoFocus
            aria-label="Type your message"
            disabled={loading}
          />
          <button type="submit" className="chat-send" disabled={loading || !input.trim()}>Send</button>
        </form>
        {error && <div style={{ color: '#b22222', marginTop: '0.5rem' }}>
          Make sure your backend server is running and your OpenAI API key is set in <code>server/.env</code>.
        </div>}
      </div>
    </main>
  );
}



// GeminiChatbot: Gemini 2.5 Pro chat with topics and structured output
function GeminiChatbot() {
  const TOPICS = [
    { label: 'Neuroscience', value: 'Neuroscience' },
    { label: 'Genetics', value: 'Genetics' },
    { label: 'Therapy', value: 'Therapy' },
    { label: 'Advocacy', value: 'Advocacy' },
    { label: 'News', value: 'Latest News' },
    { label: 'Free Text', value: '' }
  ];
  const [messages, setMessages] = useState([
    { sender: 'bot', text: 'Hi! I am your Gemini-powered Research Assistant. Select a topic or ask anything about misophonia research.' }
  ]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);
  const [selectedTopic, setSelectedTopic] = useState(null);
  const [mode, setMode] = useState('gemini'); // future: allow OpenAI fallback

  async function handleGeminiSend(e, topicOverride) {
    if (e) e.preventDefault();
    const topicVal = topicOverride !== undefined ? topicOverride : selectedTopic;
    const userText = topicVal && topicVal !== '' && topicVal !== 'Free Text' ? topicVal : input;
    if (!userText.trim()) return;
    const userMsg = { sender: 'user', text: userText };
    setMessages((msgs) => [...msgs, userMsg]);
    setLoading(true);
    setError(null);
    setInput('');
    setSelectedTopic(null);
    try {
      const res = await fetch('/api/gemini', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          messages: messages.map(m => ({ role: m.sender === 'user' ? 'user' : 'assistant', content: m.text })).concat([{ role: 'user', content: userText }]),
          topic: topicVal && topicVal !== 'Free Text' ? topicVal : undefined
        })
      });
      if (!res.ok) throw new Error('API error');
      const data = await res.json();
      setMessages((msgs) => [...msgs, { sender: 'bot', text: data.reply, structured: data.structured }]);
    } catch (err) {
      setMessages((msgs) => [...msgs, { sender: 'bot', text: 'Sorry, Gemini API error. Check your backend and API key.' }]);
      setError('API error');
    } finally {
      setLoading(false);
    }
  }

  function renderStructured(structured) {
    if (!structured) return null;
    // Example structure: { sections: [{ title, bullets, highlights, ... }], ... }
    return (
      <div className="gemini-structured">
        {structured.sections && structured.sections.map((sec, i) => (
          <div key={i} className="g-section">
            {sec.title && <div className="g-title">{sec.title}</div>}
            {sec.highlights && Array.isArray(sec.highlights) && (
              <ul className="g-highlights">{sec.highlights.map((h, j) => <li key={j} className="g-highlight">{h}</li>)}</ul>
            )}
            {sec.bullets && Array.isArray(sec.bullets) && (
              <ul className="g-bullets">{sec.bullets.map((b, j) => <li key={j}>{b}</li>)}</ul>
            )}
            {sec.text && <div className="g-text">{sec.text}</div>}
          </div>
        ))}
        {structured.extra && <div className="g-extra">{structured.extra}</div>}
      </div>
    );
  }

  return (
    <div className="gemini-chatbot">
      <div className="gemini-toggle-row">
        <button
          className={mode === 'gemini' ? 'toggle-active' : ''}
          onClick={() => setMode('gemini')}
        >Gemini 2.5 Pro</button>
        {/* <button
          className={mode === 'openai' ? 'toggle-active' : ''}
          onClick={() => setMode('openai')}
        >OpenAI</button> */}
      </div>
      <div className="gemini-topic-row">
        {TOPICS.map(t => (
          <button
            key={t.label}
            className={selectedTopic === t.value ? 'topic-btn selected' : 'topic-btn'}
            onClick={() => {
              setSelectedTopic(t.value);
              if (t.value && t.value !== 'Free Text') handleGeminiSend(null, t.value);
            }}
            disabled={loading}
          >{t.label}</button>
        ))}
      </div>
      <div className="chat-messages">
        {messages.map((msg, idx) => (
          <div key={idx} className={msg.sender === 'bot' ? 'msg bot' : 'msg user'} style={{display: 'flex', alignItems: 'flex-end', justifyContent: msg.sender === 'user' ? 'flex-end' : 'flex-start'}}>
            {msg.sender === 'bot' && (
              <img
                src={botAvatar}
                alt="Bot"
                className="chat-avatar"
                onError={e => { e.target.onerror = null; e.target.src = 'https://ui-avatars.com/api/?name=Bot&background=b2d8d8&color=fff&rounded=true&size=64'; }}
              />
            )}
            <span className="bubble-content">
              {msg.structured ? renderStructured(msg.structured) : msg.text}
            </span>
            {msg.sender === 'user' && (
              <img
                src={userAvatar}
                alt="You"
                className="chat-avatar"
                onError={e => { e.target.onerror = null; e.target.src = 'https://ui-avatars.com/api/?name=You&background=ffdac1&color=3a3a3a&rounded=true&size=64'; }}
              />
            )}
          </div>
        ))}
        {loading && <div className="msg bot" style={{display: 'flex', alignItems: 'flex-end'}}><img src={botAvatar} alt="Bot" className="chat-avatar" /><span className="bubble-content">Thinking‚Ä¶</span></div>}
      </div>
      <form className="chat-input-row" onSubmit={e => handleGeminiSend(e)}>
        <input
          type="text"
          value={input}
          onChange={e => setInput(e.target.value)}
          placeholder="Type your question or pick a topic..."
          className="chat-input"
          autoFocus
          aria-label="Type your message"
          disabled={loading}
        />
        <button type="submit" className="chat-send" disabled={loading || !input.trim()}>Send</button>
      </form>
      {error && <div style={{ color: '#b22222', marginTop: '0.5rem' }}>
        Gemini backend error. Check your server and API key in <code>server/.env</code>.
      </div>}
    </div>
  );
}

export default App


================================================================================


################################################################################
# File: scripts/docling_batch_convert_with_metadata.py
################################################################################

#!/usr/bin/env python3
# scripts/docling_batch_convert_with_metadata.py
"""
Convert every PDF under  documents/research/Global
‚Üí flat TXT (documents/research/txt/) **and** rich JSON
(documents/research/json/) that carries per‚Äëpage text plus
bibliographic metadata (title, authors, year, journal, DOI,
abstract, keywords, research_topics).

The script is idempotent: if both TXT and JSON already
exist it skips the file; if one is missing it creates just that one.
"""

from __future__ import annotations

import argparse
import json
import logging
import os
import pathlib
import re
from datetime import datetime
from typing import Any, Dict, Iterable, List

import PyPDF2
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.document_converter import DocumentConverter, PdfFormatOption
from rich.logging import RichHandler
from tqdm import tqdm

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ optional unstructured fallback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

try:
    from unstructured.partition.pdf import partition_pdf

    HAVE_UNSTRUCTURED = True
except Exception:  # pragma: no cover
    HAVE_UNSTRUCTURED = False

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ logging ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def init_logging(level: str = "INFO") -> None:
    logging.basicConfig(
        level=getattr(logging, level.upper(), "INFO"),
        format="%(asctime)s ‚Äî %(levelname)s ‚Äî %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        handlers=[RichHandler()],
    )


log = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Docling converter helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def make_converter() -> DocumentConverter:
    pdf_opts = PdfPipelineOptions()
    pdf_opts.do_ocr = True  # scan‚Äësafe
    return DocumentConverter(
        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_opts)}
    )


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ path helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def iter_pdfs(root: pathlib.Path) -> Iterable[pathlib.Path]:
    for p in root.rglob("*.pdf"):
        if p.is_file() and not p.name.startswith("."):
            yield p


def txt_path_for(src: pathlib.Path, txt_dir: pathlib.Path) -> pathlib.Path:
    return txt_dir / f"{src.stem}.txt"


def json_path_for(src: pathlib.Path, json_dir: pathlib.Path) -> pathlib.Path:
    return json_dir / f"{src.stem}.json"


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ bibliographic helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

META_FIELDS = [
    "title",
    "authors",
    "year",
    "journal",
    "doi",
    "abstract",
    "keywords",
    "research_topics",
]


def _authors(val: Any) -> List[str]:
    if val is None:
        return []
    if isinstance(val, list):
        return [str(a).strip() for a in val if a]
    return re.split(r"\s*,\s*|\s+and\s+", str(val).strip())


def extract_bib_from_filename(pdf: pathlib.Path) -> Dict[str, Any]:
    """
    Infer author/year/title from filenames like ‚ÄúSmith¬†2019¬†Some¬†Paper.pdf‚Äù.
    """
    stem = pdf.stem
    m = re.search(r"\b(19|20)\d{2}\b", stem)
    year = int(m.group(0)) if m else None
    if m:
        author = stem[: m.start()].strip()
        title = stem[m.end() :].strip(" -_")
    else:
        parts = stem.split(" ", 1)
        author = parts[0]
        title = parts[1] if len(parts) == 2 else None

    return {"authors": [author] if author else [], "year": year, "title": title}


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ header‚Äëtext regex extraction (journal / DOI ‚Ä¶) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


DOI_RE = re.compile(r"\b(10\.\d{4,9}/[-._;()/:A-Z0-9]+)", re.I)
JOURNAL_RE = re.compile(
    r"(Journal|Journals|Revista|Proceedings|Annals|Neuroscience|Psychiatry|Psychology|Nature|Science)[^\n]{0,120}",
    re.I,
)
ABSTRACT_RE = re.compile(r"(?<=\bAbstract\b[:\s])(.{50,2000}?)(?:\n[A-Z][^\n]{0,60}\n|\Z)", re.S)
KEYWORDS_RE = re.compile(r"\bKey\s*words?\b[:\s]*(.+)", re.I)


def extract_bib_from_header(header_txt: str) -> Dict[str, Any]:
    """
    Very tolerant regexes on the first pages' raw text.
    """
    meta: Dict[str, Any] = {}

    doi = DOI_RE.search(header_txt)
    if doi:
        meta["doi"] = doi.group(1)

    jour = JOURNAL_RE.search(header_txt)
    if jour:
        meta["journal"] = " ".join(jour.group(0).split())

    abst = ABSTRACT_RE.search(header_txt)
    if abst:
        meta["abstract"] = " ".join(abst.group(1).split())

    kws = KEYWORDS_RE.search(header_txt)
    if kws:
        meta["keywords"] = [k.strip(" ;.,") for k in re.split(r"[;,]", kws.group(1)) if k.strip()]

    # derive research_topics from keywords
    if meta.get("keywords"):
        meta["research_topics"] = meta["keywords"]

    return meta


def merge_metadata(*sources: Dict[str, Any]) -> Dict[str, Any]:
    """
    Deep, ordered merge of metadata sources according to META_FIELDS precedence.
    """
    merged: Dict[str, Any] = {"doc_type": "scientific paper"}
    for field in META_FIELDS:
        merged[field] = None

    for src in sources:  # earlier dicts have lower priority
        for k in META_FIELDS:
            v = src.get(k)
            if v not in (None, "", [], {}):
                merged[k] = v

    # canonical types / defaults
    merged["authors"] = _authors(merged["authors"])
    merged["keywords"] = merged["keywords"] or []
    merged["research_topics"] = merged["research_topics"] or []
    return merged


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ per‚Äëpage text extraction helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def sections_from_docling(doc) -> List[Dict[str, Any]]:
    """
    First choice: iterate doc.pages (reliable).  Fallback: split on \f.
    """
    secs: List[Dict[str, Any]] = []
    try:
        pages = getattr(doc, "pages", None)
        if pages:  # new Docling API
            for idx, page in enumerate(pages, 1):
                try:
                    txt = page.export_to_text()
                except Exception:  # pragma: no cover
                    txt = ""
                if txt and txt.strip():
                    pn = getattr(page, "metadata", {}).get("page_number", idx)
                    secs.append(
                        {
                            "section": f"Page {pn}",
                            "page_number": pn,
                            "text": txt.strip(),
                        }
                    )
        if secs:
            return secs
    except Exception as e:  # pragma: no cover
        log.debug("Docling page iteration failed: %s", e)

    # ---- fallback to page_break marker ---- #
    try:
        full = doc.export_to_text(page_break_marker="\f")
        if "\f" in full:
            for idx, txt in enumerate(full.split("\f"), 1):
                t = txt.strip()
                if t:
                    secs.append({"section": f"Page {idx}", "page_number": idx, "text": t})
        elif full.strip():
            secs.append({"section": "Page 1", "page_number": 1, "text": full.strip()})
    except Exception as e:
        log.debug("Docling export_to_text failed: %s", e)
    return secs


def sections_from_unstructured(pdf: pathlib.Path) -> List[Dict[str, Any]]:
    elements = partition_pdf(str(pdf), strategy="hi_res")
    sections: List[Dict[str, Any]] = []
    buf, cur = "", None
    for el in elements:
        page = getattr(el.metadata, "page_number", None)
        if page is None:
            continue
        if cur is None:
            cur = page
        if page != cur:
            sections.append(
                {"section": f"Page {cur}", "page_number": cur, "text": buf.strip()}
            )
            buf, cur = "", page
        buf += " " + str(el)
    if buf.strip():
        sections.append(
            {"section": f"Page {cur}", "page_number": cur, "text": buf.strip()}
        )
    return sections


def sections_from_pypdf(pdf: pathlib.Path) -> List[Dict[str, Any]]:
    secs: List[Dict[str, Any]] = []
    with open(pdf, "rb") as f:
        for i, page in enumerate(PyPDF2.PdfReader(f).pages, 1):
            try:
                txt = page.extract_text() or ""
            except Exception:
                txt = ""
            secs.append({"section": f"Page {i}", "page_number": i, "text": txt.strip()})
    return secs


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ single‚Äëfile processing pipeline ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def process_one(
    conv: DocumentConverter,
    pdf: pathlib.Path,
    txt_dir: pathlib.Path,
    json_dir: pathlib.Path,
    overwrite: bool,
) -> bool:
    txt_path = txt_path_for(pdf, txt_dir)
    json_path = json_path_for(pdf, json_dir)

    has_txt, has_json = txt_path.exists(), json_path.exists()
    if has_txt and has_json and not overwrite:
        log.debug("‚úì Skip %s (TXT+JSON present)", pdf.name)
        return False

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Docling first ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
    doc_meta: Dict[str, Any] = {}
    sections: List[Dict[str, Any]] = []
    try:
        bundle = conv.convert(str(pdf))
        doc = bundle.document
        meta_obj = getattr(doc, "metadata", None)
        if meta_obj is not None:
            for meth in ("model_dump", "dict", "to_dict"):
                if hasattr(meta_obj, meth):
                    doc_meta = getattr(meta_obj, meth)()
                    break
        sections = sections_from_docling(doc)
    except Exception as e:
        log.debug("Docling failed on %s (%s) ‚Äì trying fallbacks", pdf.name, e)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ fallbacks if Docling text inadequate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
    if not sections or all(len(s["text"]) < 40 for s in sections):
        if HAVE_UNSTRUCTURED:
            try:
                sections = sections_from_unstructured(pdf)
            except Exception as e:
                log.debug("unstructured failed on %s (%s)", pdf.name, e)
        if not sections:
            sections = sections_from_pypdf(pdf)

    if not sections:
        raise RuntimeError("no text extracted")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ compile metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
    first_pages_text = " ".join(s["text"] for s in sections[:2])[:12000]
    header_meta = extract_bib_from_header(first_pages_text)
    filename_meta = extract_bib_from_filename(pdf)
    meta = merge_metadata(doc_meta, filename_meta, header_meta)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ assemble JSON payload ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
    payload = {
        **meta,
        "created_at": datetime.utcnow().isoformat() + "Z",
        "source_pdf": str(pdf),
        "sections": sections,
    }

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ write outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
    if overwrite or not has_json:
        json_path.parent.mkdir(parents=True, exist_ok=True)
        json_path.write_text(
            json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8"
        )

    if overwrite or not has_txt:
        txt_path.parent.mkdir(parents=True, exist_ok=True)
        txt_path.write_text("\n\n".join(s["text"] for s in sections), encoding="utf-8")

    return True


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ batch driver ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def run(
    src_root: pathlib.Path,
    txt_dir: pathlib.Path,
    json_dir: pathlib.Path,
    overwrite: bool,
    limit: int | None,
) -> None:
    conv = make_converter()
    pdfs = list(iter_pdfs(src_root))
    if limit:
        pdfs = pdfs[:limit]

    processed = skipped = failed = 0
    log.info("Starting ‚Äì %s PDFs (src=%s)", len(pdfs), src_root)

    with tqdm(total=len(pdfs), unit="file", desc="Processing") as bar:
        for pdf in pdfs:
            bar.set_postfix_str(pdf.name)
            try:
                changed = process_one(conv, pdf, txt_dir, json_dir, overwrite)
                if changed:
                    processed += 1
                else:
                    skipped += 1
            except Exception as e:
                failed += 1
                log.error("‚ÄºÔ∏è  %s failed: %s", pdf.name, e)
            bar.update()

    log.info(
        "Done. processed=%s  skipped=%s  failed=%s  (TXT ‚Üí %s , JSON ‚Üí %s)",
        processed,
        skipped,
        failed,
        txt_dir,
        json_dir,
    )


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def cli() -> None:
    p = argparse.ArgumentParser(
        description="Convert research PDFs to TXT and JSON with metadata"
    )
    p.add_argument("--src", default="documents/research/Global", help="PDF folder")
    p.add_argument("--txt-dir", default="documents/research/txt", help="TXT output dir")
    p.add_argument("--json-dir", default="documents/research/json", help="JSON output dir")
    p.add_argument("--overwrite", action="store_true", help="Force re‚Äëcreate outputs")
    p.add_argument(
        "--log",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="Console log level",
    )
    p.add_argument("--max", type=int, default=0, help="Process at most N PDFs")
    args = p.parse_args()

    init_logging(args.log)
    run(
        pathlib.Path(args.src),
        pathlib.Path(args.txt_dir),
        pathlib.Path(args.json_dir),
        args.overwrite,
        None if args.max == 0 else args.max,
    )


if __name__ == "__main__":
    cli()


================================================================================


################################################################################
# File: src/App.css
################################################################################

/* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */
/* GLOBAL RESET                                 */
html, body {
  margin: 0 !important;      /* kill the 8 px UA margin */
  padding: 0;
  height: 100%;              /* body fills the viewport vertically */
}

/* optional ‚Äì keeps sizing predictable everywhere */
*, *::before, *::after { box-sizing: border-box; }
/* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */

/* ----- BODY --------------------------------------------- */
body {
  min-height: 100vh;
  margin: 0;
  font-family: 'Nunito', 'Segoe UI', 'Helvetica Neue', Arial, 'Liberation Sans', sans-serif;
  color: #3a3a3a;
  background: linear-gradient(120deg, #f8f6ff 0%, #b2d8d8 100%);
  overflow-x: hidden;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.animated-bg {
  position: fixed;
  z-index: 0;
  width: 100vw;
  height: 100vh;
  top: 0; left: 0;
  pointer-events: none;
  overflow: hidden;
}

.bubble {
  position: absolute;
  border-radius: 50%;
  opacity: 0.3;
  animation: float 18s infinite linear;
  background: #b2d8d8;
}
.bubble1 { width: 120px; height: 120px; left: 10vw; top: 80vh; animation-delay: 0s; background: #b2d8d8; }
.bubble2 { width: 80px; height: 80px; left: 70vw; top: 70vh; animation-delay: 4s; background: #f8f6ff; }
.bubble3 { width: 90px; height: 90px; left: 50vw; top: 90vh; animation-delay: 8s; background: #e0e7ef; }
.bubble4 { width: 60px; height: 60px; left: 20vw; top: 85vh; animation-delay: 2s; background: #f7cac9; }
.bubble5 { width: 100px; height: 100px; left: 80vw; top: 95vh; animation-delay: 6s; background: #b5ead7; }
.bubble6 { width: 70px; height: 70px; left: 30vw; top: 92vh; animation-delay: 10s; background: #ffdac1; }
.bubble7 { width: 110px; height: 110px; left: 60vw; top: 85vh; animation-delay: 12s; background: #c7ceea; }
.bubble8 { width: 50px; height: 50px; left: 40vw; top: 98vh; animation-delay: 14s; background: #f6dfeb; }
@keyframes float {
  0% { transform: translateY(0); }
  100% { transform: translateY(-90vh); }
}

/* ----- LAYOUT WRAPPER ----------------------------------- */
.container {
  max-width: 860px;
  margin: 0 auto;
  padding: 0 1rem;
  width: 100%;

  display: flex;
  flex-direction: column;
  align-items: center;

  z-index: 1;
  position: relative;
  min-width: 340px;
  background: none;
  box-shadow: none;
}

/* ----- CARD --------------------------------------------- */
.card {
  background: rgba(255,255,255,0.96);
  border-radius: 22px;
  box-shadow: 0 6px 32px rgba(31,38,135,.13);
  padding: 2rem 1.2rem;
  margin: 2.5rem 0;
  max-width: 520px;
  width: 100%;
  display: flex;
  flex-direction: column;
  align-items: center;
  transition: box-shadow 0.18s;
}

/* mobile tweaks ‚Äì ONE block */
@media (max-width: 700px) {
  .container { 
    max-width: 98vw; 
    padding: 1rem; 
  }
  .card { 
    padding: 1.2rem 0.5rem; 
    border-radius: 16px; 
    max-width: 99vw;
  }
  .navbar {
    flex-direction: column;
    flex-wrap: wrap;
    gap: 0.5rem;
    font-size: 0.97rem;
  }
  .chatbot-box {
    padding: 1rem 0.3rem;
    border-radius: 16px;
  }
  .msg {
    font-size: 0.99rem;
  }
  .chat-avatar {
    width: 30px; height: 30px;
  }
}

/* ----- NAVBAR ------------------------------------------- */
.navbar {
  display: flex;
  justify-content: center;
  gap: 1rem;
  flex-wrap: wrap;
  margin-bottom: 2rem;
}

.navbar button {
  background: #e6e6fa;
  color: #3a3a3a;
  border: none;
  padding: 0.7rem 1.5rem;
  border-radius: 18px;
  font-size: 1rem;
  font-weight: 500;
  cursor: pointer;
  transition: background 0.2s, color 0.2s;
  box-shadow: 0 2px 8px rgba(178, 216, 216, 0.09);
}

.navbar button.active, .navbar button:hover {
  background: #b2d8d8;
  color: #234e52;
}

.title {
  font-size: 2.2rem;
  margin-bottom: 0.5rem;
  color: #234e52;
  font-family: 'Segoe UI', 'Helvetica Neue', Arial, 'Liberation Sans', sans-serif;
}

.subtitle {
  font-size: 1.2rem;
  color: #6d7b8d;
  margin-bottom: 2rem;
}

main {
  padding: 1.5rem 0;
}

h2 {
  color: #234e52;
  margin-bottom: 1rem;
}

/* Chatbot styles (always apply) */
.chatbot-box {
  background: linear-gradient(135deg, rgba(248,246,255,0.93) 60%, rgba(178,216,216,0.10) 100%);
  border-radius: 26px;
  box-shadow: 0 4px 28px 0 rgba(31, 38, 135, 0.11), 0 1.5px 5px 0 rgba(178,216,216,0.08);
  padding: 2.2rem 1.2rem 1.5rem 1.2rem;
  margin: 0.5rem 0 0.5rem 0;
  min-height: 350px;
  width: 100%;
  display: flex;
  flex-direction: column;
  border: 1.5px solid #e0e7ef;
  backdrop-filter: blur(3px);
  position: relative;
  transition: box-shadow 0.2s;
}

.chat-messages {
  flex: 1;
  overflow-y: auto;
  margin-bottom: 1.1rem;
  display: flex;
  flex-direction: column;
  gap: 0.7rem;
  padding-bottom: 0.5rem;
  border-radius: 18px 18px 8px 8px;
  animation: fadeIn 0.7s;
}
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(16px); }
  to { opacity: 1; transform: translateY(0); }
}

.msg {
  max-width: 80%;
  display: flex;
  align-items: flex-end;
  gap: 0.6rem;
  font-size: 1.08rem;
  word-break: break-word;
  box-shadow: 0 1px 6px 0 rgba(31, 38, 135, 0.03);
  margin-bottom: 0.1rem;
}

.msg.user {
  align-self: flex-end;
  flex-direction: row-reverse;
}

.msg.bot {
  align-self: flex-start;
}

.bubble-content {
  padding: 0.7rem 1.1rem;
  border-radius: 16px;
  background: linear-gradient(90deg, #b2d8d8 60%, #e0e7ef 100%);
  color: #2a3d3d;
  font-size: 1.08rem;
  box-shadow: 0 1px 6px 0 rgba(31, 38, 135, 0.03);
}

.msg.bot .bubble-content {
  background: linear-gradient(90deg, #f8f6ff 60%, #e9f7f7 100%);
  color: #5b3a6b;
}

.chat-avatar {
  width: 38px;
  height: 38px;
  border-radius: 50%;
  margin: 0 0.2rem;
  box-shadow: 0 2px 8px 0 rgba(31, 38, 135, 0.05);
  background: #fff;
  object-fit: cover;
}

.chat-input-row {
  display: flex;
  gap: 0.6rem;
  border-top: 1.5px solid #e0e7ef;
  padding-top: 1rem;
  margin-top: 0.3rem;
  align-items: center;
}

.chat-input {
  flex: 1;
  height: 48px;
  padding: 0 1rem;
  border-radius: 12px;
  border: 1.5px solid #c6e2e2;
  font-size: 1.08rem;
  outline: none;
  background: #f4fafd;
  color: #2a3d3d;
  box-sizing: border-box;
  transition: border-color 0.18s;
}

.chat-input:focus {
  border-color: #b2d8d8;
}

.chat-send {
  height: 48px;
  min-width: 90px;
  padding: 0 1.2rem;
  border-radius: 12px;
  border: none;
  background: #b2d8d8;
  color: #fff;
  font-weight: bold;
  font-size: 1.08rem;
  cursor: pointer;
  transition: background 0.2s, box-shadow 0.18s;
  box-shadow: 0 1.5px 6px 0 rgba(31, 38, 135, 0.07);
  display: flex;
  align-items: center;
  justify-content: center;
}

.chat-send:hover:not(:disabled) {
  background: #81b0b0;
  box-shadow: 0 4px 16px 0 rgba(31, 38, 135, 0.13);
}

.chat-send:disabled {
  background: #f4fafd;
  color: #b2d8d8;
  cursor: not-allowed;
  border: 1.5px solid #e0e7ef;
  box-shadow: none;
}

/* More forceful styling for avatar labels */
.chat-avatar, [class*="avatar"], [class*="circle"] {
  font-size: 10px !important;
  width: 45px !important;
  height: 45px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
}

/* ----- RESEARCH-ASSISTANT POP-UP ------------------------ */
.ra-wrapper {
  position: fixed;            /* stick to viewport */
  bottom: 84px;               /* enough to clear the floating disclaimer */
  left: 50%;
  transform: translateX(-50%);
  width: min(1100px, 96vw);    /* A little wider on desktop, still fully responsive on phones */
  max-height: 70vh;           /* room for long answers w/ scroll */
  overflow-y: auto;
  border-radius: 18px;
  background: #ffffff;
  box-shadow: 0 8px 22px rgba(0,0,0,.07);
  padding: 2rem 2.25rem;
}

/* ‚îÄ‚îÄ‚îÄ research-assistant sticky search bar ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */
.rag-form{
  position: sticky;
  bottom: 0;                  /* hugs the card's bottom edge            */
  z-index: 2;
  padding: 1rem 0 0.5rem;     /* little breathing room                  */
  background: rgba(255,255,255,.96);   /* white backdrop while it floats */
  backdrop-filter: blur(3px);
}

.ra-input-row {
  display: flex;
  gap: 0.6rem;
  margin-bottom: 1.25rem;
}

.ra-input {
  flex: 1 1 auto;
  font-size: 1.05rem;
  padding: 0.65rem 0.9rem;
  border: 2px solid #d0e4e4;
  border-radius: 10px;
}

.ra-btn {
  background: #669c99;
  color: #fff;
  border: 0;
  padding: 0 1.25rem;
  border-radius: 10px;
  font-weight: 600;
  cursor: pointer;
}

/* ----- DISCLAIMER (single source of truth) --------------- */
.disclaimer-footer {
  position: fixed;
  bottom: 0;            /* 0 means literally the last pixel */
  left: 0;
  width: 100%;
  font-size: 0.75rem;
  color: #666;
  text-align: center;
  padding: 0;       /* adjust or set to 0 for no inner gap */
  background: transparent;      /* or rgba(255,255,255,.85) if you want a strip */
  z-index: 30;          /* higher than bubbles / page cards */
}

/* ‚îÄ‚îÄ‚îÄ RAG assistant layout tweak ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */
.rag-card {
  max-height: 75vh;               /* card never taller than viewport */
  overflow-y: auto;               /* inner scroll, NOT page scroll   */
  display: flex;
  flex-direction: column;         /* children stack top‚Üíbottom       */
}

/* scrolling area for answer + sources */
.rag-body {
  flex: 1 1 auto;                 /* fill remaining height           */
  overflow-y: auto;
}

/* search row always visible inside the scrolling card */
.rag-input-row {
  flex-shrink: 0;                 /* never shrinks                   */
  position: sticky;
  bottom: 0;                      /* sticks to card's bottom         */
  background: #fff;               /* white strip over scrolled text  */
  padding-top: 1rem;              /* add gap so it doesn't hug text  */
}

/* ‚îÄ‚îÄ‚îÄ RAG card: same width as before, inner scroll, sticky input ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */
.ra-card {
  width: 100%;                 /* full width of the central container    */
  max-width: 1000px;           /* equals the old Bootstrap template      */
  margin: 0 auto;              /* keep it centred                        */

  /* original "card" visual style (copied, not changed) */
  background: rgba(255,255,255,0.96);
  border-radius: 22px;
  box-shadow: 0 6px 32px rgba(31,38,135,.13);
  padding: 2rem 1.2rem;

  /* NEW: make the inside scroll but freeze the input row */
  display: flex;
  flex-direction: column;
  max-height: 75vh;            /* never taller than the viewport         */
  overflow-y: auto;
}

/* scrolling part (answer + citations) */
.ra-body {
  flex: 1 1 auto;
  overflow-y: auto;
}

/* sticky search row ‚Äì always visible */
.ra-input-row {
  flex-shrink: 0;
  position: sticky;
  bottom: 0;
  background: #fff;            /* white strip so text doesn't peek under */
  padding-top: 1rem;           /* gap between content & bar              */
}

/* RAG research card & footer separation ---------------- */
.ra-card, .rag-card {
  /* just ~1 em gap ‚Äì enough to clear the footer without a chasm */
  margin-bottom: 1.3rem;
}

/* keep the search bar fixed just above the footer text (‚âà24 px) */
.ra-input-row {
  position: sticky;
  bottom: 1.5rem;
}


================================================================================


################################################################################
# File: scripts/optimized_batch_process_gian_v1.py
################################################################################

# File: scripts/optimized_batch_process_gian_v1.py

#!/usr/bin/env python3
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
"""
Batch‚Äëupload pre‚Äëparsed research papers into Supabase
using a fixed‚Äëtoken sliding window (768‚ÄØtokens, 20‚ÄØ% overlap).

INPUT  directories
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
documents/research/json   one JSON per paper (metadata + per‚Äëpage text)
documents/research/txt    flat .txt version (kept for future re‚Äëchunking)

DB schema expected
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  research_documents  (one row per paper)
  research_chunks     (token_window strategy)

Chunking parameters
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ window      768 tokens
  ‚Ä¢ overlap     154 tokens   (20‚ÄØ%)
  ‚Ä¢ step        614 tokens   (window ‚àí overlap)

Sentence‚Äëfriendly rule
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
After *window* tokens are gathered we keep adding UNTIL the next token
ends with `.`, `!`, or `?` ‚Äîor the file ends, or we exceed
window‚ÄØ+‚ÄØ256 tokens.  This avoids mid‚Äësentence splits whenever possible.
"""
from __future__ import annotations

import argparse
import json
import os
import random
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Sequence

from dotenv import load_dotenv
from supabase import create_client
from tqdm import tqdm

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ env / constants ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

load_dotenv()

REPO_ROOT      = Path(__file__).resolve().parent.parent
JSON_DIR       = REPO_ROOT / "documents" / "research" / "json"
TXT_DIR        = REPO_ROOT / "documents" / "research" / "txt"   # kept but unused here

SUPABASE_URL   = os.getenv("SUPABASE_URL")
SUPABASE_KEY   = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

DEFAULT_WINDOW   = 768
DEFAULT_OVERLAP  = int(DEFAULT_WINDOW * 0.20)     # 154
DEFAULT_STEP     = DEFAULT_WINDOW - DEFAULT_OVERLAP
SENT_END_RE      = re.compile(r"[.!?]$")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NUL‚Äëbyte scrubber ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

def scrub_nuls(obj: Any) -> Any:
    """Recursively remove ASCII‚ÄëNUL characters from any str inside *obj*."""
    if isinstance(obj, str):
        return obj.replace("\x00", "")
    if isinstance(obj, list):
        return [scrub_nuls(x) for x in obj]
    if isinstance(obj, dict):
        return {k: scrub_nuls(v) for k, v in obj.items()}
    return obj

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

def discover_json_files() -> List[Path]:
    return sorted(JSON_DIR.rglob("*.json"))

def load_paper(json_path: Path) -> Dict[str, Any]:
    return json.loads(json_path.read_text(encoding="utf‚Äë8"))

def concat_sections(sections: Sequence[Dict[str, Any]]) -> tuple[list[str], list[int]]:
    """
    Return (tokens, token_to_page)  ‚Ü¶  token_to_page[i] = 1‚Äëbased page number.
    """
    tokens: list[str] = []
    page_map: list[int] = []
    for sec in sections:
        page = sec.get("page_number") or 1
        sec_tokens = sec.get("text", "").split()
        tokens.extend(sec_tokens)
        page_map.extend([page] * len(sec_tokens))
    return tokens, page_map

def sliding_window_chunks(
    tokens: List[str],
    page_map: List[int],
    *,
    window: int = DEFAULT_WINDOW,
    overlap: int = DEFAULT_OVERLAP,
) -> List[Dict[str, Any]]:
    """Fixed‚Äëtoken windows with overlap, but avoid cutting sentences."""
    step = max(1, window - overlap)
    chunks: list[dict[str, Any]] = []
    i = 0
    safety_extra = 256

    while i < len(tokens):
        start = i
        end   = min(len(tokens), start + window)

        # extend to sentence boundary if possible
        while (
            end < len(tokens)
            and not SENT_END_RE.search(tokens[end - 1])
            and (end - start) < window + safety_extra
        ):
            end += 1

        text_slice  = " ".join(tokens[start:end])
        page_start  = page_map[start]
        page_end    = page_map[end - 1]
        chunk_idx   = len(chunks)

        chunks.append(
            {
                "chunk_index":  chunk_idx,
                "token_start":  start,
                "token_end":    end - 1,
                "page_start":   page_start,
                "page_end":     page_end,
                "text":         scrub_nuls(text_slice),
            }
        )
        if end == len(tokens):
            break
        i += step

    return chunks

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Supabase I/O ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

def get_processed_pdfs(sb) -> set[str]:
    """
    Return the set of source_pdf paths already present in research_documents.
    """
    try:
        rows = sb.table("research_documents").select("source_pdf").execute().data or []
        return {row["source_pdf"] for row in rows}
    except Exception as e:
        print(f"[get_processed_pdfs] {e}")
        return set()

BIB_KEYS = {
    "doc_type", "title", "authors", "year",
    "journal", "doi", "abstract", "keywords",
    "research_topics", "source_pdf",
}

def insert_document(sb, raw_meta: Dict[str, Any]) -> str:
    """
    Insert into research_documents; returns UUID.  Re‚Äëuse row if DOI matches.
    """
    raw_meta = scrub_nuls(raw_meta)
    doi = raw_meta.get("doi")

    # ‚îÄ‚îÄ 1.  reuse if DOI already there
    if doi:
        q = (
            sb.table("research_documents")
            .select("id")
            .eq("doi", doi)
            .limit(1)
            .execute()
        )
        if q.data:
            return q.data[0]["id"]

    # ‚îÄ‚îÄ 2.  trim to bibliographic subset
    meta_small = {k: raw_meta.get(k) for k in BIB_KEYS}

    payload = {
        **meta_small,
        # defaults / housekeeping
        "doc_type":   meta_small.get("doc_type", "scientific paper"),
        "authors":    meta_small.get("authors") or [],
        "keywords":   meta_small.get("keywords") or [],
        "research_topics": meta_small.get("research_topics") or [],
        "metadata":   meta_small,                 # stored as jsonb
        "created_at": datetime.utcnow().isoformat(),
    }
    res = sb.table("research_documents").insert(payload).execute()
    if getattr(res, "error", None):
        raise RuntimeError(res.error)
    return res.data[0]["id"]

def insert_chunks(sb, doc_id: str, json_path: Path, chunks: Sequence[Dict[str, Any]]):
    max_batch = 500
    rows = [
        {
            "document_id":       doc_id,
            "chunk_index":       ch["chunk_index"],
            "token_start":       ch["token_start"],
            "token_end":         ch["token_end"],
            "page_start":        ch["page_start"],
            "page_end":          ch["page_end"],
            "text":              ch["text"],
            "metadata":          json.loads(json.dumps({}).replace('\u0000', '')),  # extra per‚Äëchunk data (now clean)
            "chunking_strategy": "token_window",
            "source_file":       json_path.as_posix(),  # ‚Üê renamed column
            "created_at":        datetime.utcnow().isoformat(),
        }
        for ch in chunks
    ]
    for i in range(0, len(rows), max_batch):
        sb.table("research_chunks").insert(rows[i : i + max_batch]).execute()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ main process ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

def process_one_paper(
    sb,
    json_path: Path,
    *,
    window: int,
    overlap: int,
) -> tuple[bool, str]:
    try:
        paper = load_paper(json_path)
        sections = paper.get("sections") or []
        if not sections:
            return False, "No sections/text found."

        tokens, page_map = concat_sections(sections)
        if not tokens:
            return False, "Empty token list."

        chunks = sliding_window_chunks(tokens, page_map, window=window, overlap=overlap)
        doc_id = insert_document(sb, paper)
        insert_chunks(sb, doc_id, json_path, chunks)
        return True, f"{len(chunks)} chunks"
    except Exception as e:
        return False, str(e)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

def main() -> None:
    p = argparse.ArgumentParser(description="Upload 768‚Äëtoken window chunks to Supabase")
    p.add_argument("--batch-size", type=int, default=20, help="papers per run (0 = all)")
    p.add_argument("--window",     type=int, default=DEFAULT_WINDOW, help="tokens per chunk")
    p.add_argument("--overlap",    type=int, default=DEFAULT_OVERLAP, help="token overlap")
    p.add_argument("--selection",  choices=["sequential", "random"], default="sequential")
    args = p.parse_args()

    if not (SUPABASE_URL and SUPABASE_KEY):
        sys.exit("‚ùå  Missing SUPABASE_URL / SUPABASE_SERVICE_ROLE_KEY")

    sb = create_client(SUPABASE_URL, SUPABASE_KEY)

    all_json = discover_json_files()
    processed_pdfs = get_processed_pdfs(sb)
    remaining = [
        p for p in all_json
        if scrub_nuls(load_paper(p)).get("source_pdf") not in processed_pdfs
    ]

    if args.selection == "random" and args.batch_size and len(remaining) > args.batch_size:
        remaining = random.sample(remaining, args.batch_size)
    elif args.batch_size:
        remaining = remaining[: args.batch_size]

    if not remaining:
        print("‚ú®  Nothing new to process.")
        return

    step = args.window - args.overlap
    print(f"Uploading {len(remaining)} papers ‚Ä¶  (window={args.window}, overlap={args.overlap}, step={step})")
    ok = fail = 0
    for jp in tqdm(remaining, desc="Papers"):
        success, msg = process_one_paper(
            sb,
            jp,
            window=args.window,
            overlap=args.overlap,
        )
        if success:
            ok += 1
        else:
            fail += 1
            print(f"  ! {jp.name} ‚Üí {msg}")

    print(f"\nDone ‚úî   success={ok}   failed={fail}")

if __name__ == "__main__":
    main()


================================================================================


################################################################################
# File: src/TermsModal.jsx
################################################################################

import React, { useState } from 'react';

export default function TermsModal({ onAccept }) {
  const [checked, setChecked] = useState(false);
  return (
    <div style={{ position:'fixed', top:0, left:0, right:0, bottom:0, backgroundColor:'rgba(0,0,0,0.7)', zIndex:1000, display:'flex', alignItems:'center', justifyContent:'center', border:'4px dashed red' }}>
      <div style={{ background:'#fff', padding:'2rem', maxWidth:'600px', width:'80%', boxSizing:'border-box', maxHeight:'80vh', overflowY:'auto', borderRadius:'8px', display:'flex', flexDirection:'column', alignItems:'center', border:'4px solid blue' }}>
        <h2>Terms and Conditions</h2>
        <div style={{ overflowY:'auto', maxHeight:'50vh', textAlign:'left', width:'100%' }}>
          <p><strong>Effective Date:</strong> [Insert Date]</p>
          <p><strong>1. Acceptance of Terms</strong> By accessing or using the Misophonia Companion application ('App'), you agree to be bound by these Terms and Conditions ('Terms'). If you do not agree to these Terms, do not use the App.</p>
          <p><strong>2. Nature of the App</strong> Misophonia Companion is a digital wellness and research guide. It is intended for informational, educational, and personal support purposes only. The App does not provide medical advice, diagnosis, or treatment. It is not a licensed healthcare service and is not intended to replace professional consultation.</p>
          <p><strong>3. Eligibility</strong> You must be at least 16 years old to use the App. If you are under 18, you confirm that you have received parental or guardian consent.</p>
          <p><strong>4. Privacy and Data</strong> We respect your privacy. Our Privacy Policy explains how we collect, use, and protect your information. By using the App, you agree to the terms of our Privacy Policy.</p>
          <p>No health information (as defined under HIPAA) is collected without explicit consent.</p>
          <p>Conversations may be stored anonymously for product improvement unless you opt out.</p>
          <p>We do not sell or share your data with third parties for advertising purposes.</p>
          <p><strong>5. User Conduct</strong> You agree to use the App responsibly and not to misuse the services, including but not limited to:</p>
          <ul>
            <li>Attempting to reverse-engineer, copy, or modify the App</li>
            <li>Submitting harmful, abusive, or misleading content</li>
            <li>Interfering with the operation or integrity of the App</li>
          </ul>
          <p><strong>6. Limitation of Liability</strong> To the fullest extent permitted by law, Misophonia Companion and its creators are not liable for any direct, indirect, incidental, or consequential damages resulting from the use‚Äîor inability to use‚Äîthe App. This includes, but is not limited to, psychological distress, loss of data, or misinterpretation of information.</p>
          <p><strong>7. Modifications to the Terms</strong> We reserve the right to modify these Terms at any time. Continued use of the App after changes means you accept the new Terms.</p>
          <p><strong>8. Termination</strong> We may suspend or terminate access to the App at our discretion, without notice, for conduct that violates these Terms.</p>
          <p><strong>9. Governing Law</strong> These Terms are governed by the laws of the state of [Your State], without regard to conflict of laws principles.</p>
          <p><strong>10. Contact</strong> For questions or concerns about these Terms, please email: [Your Contact Email]</p>
        </div>
        <h2>Privacy Policy</h2>
        <div style={{ overflowY:'auto', maxHeight:'30vh', textAlign:'left', width:'100%' }}>
          <p><strong>Effective Date:</strong> [Insert Date]</p>
          <p><strong>1. Introduction</strong> This Privacy Policy describes how Misophonia Companion ('we', 'us', 'our') collects, uses, and protects your personal information when you use our web and mobile application ('App').</p>
          <p><strong>2. Information We Collect</strong></p>
          <p><strong>‚Ä¢</strong> <em>User-Provided Information</em>: When you create an account or interact with the App, you may provide personal information such as your email address and preferences.</p>
          <p><strong>‚Ä¢</strong> <em>Anonymous Usage Data</em>: We may collect anonymized data on app usage, interactions, and conversation content to improve the experience.</p>
          <p><strong>‚Ä¢</strong> <em>Optional Personal Logs</em>: Users may opt in to mood tracking, journaling, or trigger tagging. This data is stored securely and only accessible to the user unless explicitly shared.</p>
          <p><strong>3. How We Use Your Information</strong> To provide and improve our services; to personalize your user experience; for anonymized research and development; to comply with legal obligations if required.</p>
          <p><strong>4. Data Storage and Security</strong> We use secure, encrypted servers and industry-standard protocols to store your data. Sensitive data is never shared with third parties without consent. You may request deletion of your account and data at any time.</p>
          <p><strong>5. Sharing and Disclosure</strong> We do not sell or rent your personal information. We may share anonymized data with research collaborators or analytics partners. We may disclose information if legally compelled (e.g., court order).</p>
          <p><strong>6. Your Rights and Choices</strong> You may update or delete your personal information from your profile. You may opt out of data collection for research purposes. You may contact us for a copy of any personal data we‚Äôve stored.</p>
          <p><strong>7. Children‚Äôs Privacy</strong> Our App is not intended for children under 16. We do not knowingly collect data from individuals under this age without parental consent.</p>
          <p><strong>8. Changes to This Policy</strong> We may revise this policy from time to time. Users will be notified of significant changes. Continued use of the App indicates acceptance of the updated policy.</p>
          <p><strong>9. Contact Us</strong> If you have questions or requests related to this Privacy Policy, please contact us at: [Your Contact Email]</p>
        </div>
        <label style={{ display:'block', margin:'1rem 0', textAlign:'center', width:'100%' }}>
          <input type='checkbox' checked={checked} onChange={e => setChecked(e.target.checked)} /> I have read and agree to the Terms and Conditions and Privacy Policy
        </label>
        <button disabled={!checked} onClick={() => { localStorage.setItem('termsAccepted','true'); onAccept(); }} style={{ marginTop:'1.5rem', padding:'0.5rem 1rem' }}>Continue</button>
      </div>
    </div>
  );
}


================================================================================


################################################################################
# File: scripts/test_vector_search.py
################################################################################

#!/usr/bin/env python3
################################################################################
################################################################################
"""
Vector‚Äësearch smoke‚Äëtest (Supabase edition)
==========================================

‚Ä¢ Firebase/Firestore has been removed ‚Äî every data call now goes through
  Supabase's PostgREST API.

‚Ä¢ The script calls a SQL helper function that must exist on your database:
    public.search_research_chunks(query_text TEXT,
                                  match_count INT DEFAULT 10,
                                  similarity_threshold REAL DEFAULT 0.6)
  which should:
    1. embed the incoming `query_text`
    2. invoke your `match_documents` similarity function
    3. return the top‚Äë`match_count` rows as
       (id UUID, text TEXT, metadata JSONB, similarity REAL)

  See README / earlier instructions for a ready‚Äëmade implementation.

Environment variables required
------------------------------
SUPABASE_URL                 ‚Äì e.g. https://xxxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY    ‚Äì or an anon key if RLS permits the RPC
OPENAI_API_KEY               ‚Äì only if your SQL helper embeds via an HTTP call
"""

from __future__ import annotations

import os
import sys
import time
from typing import Any, Dict, List

from dotenv import load_dotenv
from supabase import create_client
from openai import OpenAI

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ configuration & sanity checks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #

load_dotenv()

# ---------- Supabase config ----------
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")   # or anon if RLS permits
sb = create_client(SUPABASE_URL, SUPABASE_KEY)

if not SUPABASE_URL or not SUPABASE_KEY:
    sys.exit(
        "‚ùå  SUPABASE_URL / SUPABASE_SERVICE_ROLE_KEY env vars are missing.\n"
        "    export them and rerun."
    )

# Sample questions to probe the index
SAMPLE_QUERIES: List[str] = [
    "What are the symptoms of misophonia?",
    "How prevalent is misophonia in university students?",
    "What is the relationship between misophonia and hyperacusis?",
    "What treatments are effective for misophonia?",
    "How does misophonia affect quality of life?",
]

# Add this after other configuration
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def embed(text: str) -> List[float]:
    """Return OpenAI ada‚Äë002 embedding (1536‚Äëdim list of floats)."""
    resp = openai_client.embeddings.create(
        model="text-embedding-ada-002",
        input=text,
    )
    return resp.data[0].embedding

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helper functions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def perform_vector_search(query_vec, top_k=5, thresh=0.6):
    """
    Call the SQL RPC we just created.
    `query_vec` is a list[float] length 1536 coming from OpenAI.
    """
    try:
        resp = sb.rpc(
            "search_research_chunks",
            {
                "query_embedding": query_vec,
                "match_count": top_k,
                "similarity_threshold": thresh,
            },
        ).execute()
        if getattr(resp, "error", None):
            raise RuntimeError(resp.error)
        return resp.data or []
    except Exception as e:
        print(f"   ‚ö†  RPC failed: {e}")
        return []


def print_results(rows: List[Dict[str, Any]]) -> None:
    """
    Nicely format the search results.
    """
    if not rows:
        print("   (no matches)\n")
        return

    for idx, row in enumerate(rows, 1):
        meta = row.get("metadata", {}) or {}
        title = meta.get("title", "Unknown title")
        year = meta.get("year", "????")
        author = meta.get("primary_author", "Unknown author")
        sim = row.get("similarity", 0.0)

        snippet = (row.get("text", "") or "").replace("\n", " ")[:280] + "‚Ä¶"

        print(f"\nResult {idx}  ‚Ä¢  sim={sim:.3f}")
        print(f"  {title} ‚Äî {author} ({year})")
        print(f"  {snippet}")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ main ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #


def main() -> None:
    print("\nüîç  Supabase vector search smoke‚Äëtest\n" + "‚Äî" * 60)
    for i, q in enumerate(SAMPLE_QUERIES, 1):
        print(f'\nQuery {i + 1}/{len(SAMPLE_QUERIES)}: "{q}"')


        # 1. get the vector
        print("Generating embedding...")
        query_vec = embed(q)  # Python list[float]

        # 2. PostgREST / Postgres expects a *string* like: [0.1,0.2,‚Ä¶]
        vec_literal = "[" + ",".join(f"{x:.6f}" for x in query_vec) + "]"

        # 3. call the RPC
        print("Performing vector search...")
        resp = sb.rpc(
            "search_research_chunks",
            {
                "query_embedding": vec_literal,  # <- NOT the raw text
                "match_count": 5,
                "similarity_threshold": 0.6,
            },
        ).execute()
        
        if getattr(resp, "error", None):
            print(f"   ‚ö†  RPC failed: {resp.error}\n")
            continue
            
        results = resp.data or []
        print_results(results)

        if i < len(SAMPLE_QUERIES):
            print("\nPausing 2 s before the next query ‚Ä¶")
            time.sleep(2)

    print("\n‚úî  Done")


if __name__ == "__main__":
    main()


================================================================================


################################################################################
# File: README.md
################################################################################

################################################################################
################################################################################

<!-- PROJECT LOGO -->
<p align="center">
  <img src="public/vite.svg" alt="Logo" width="120" height="120">

</p>

<h1 align="center">Misophonia Companion</h1>

<p align="center">
  <b>The modern, AI-powered guide and support tool for those living with misophonia.</b><br>
  <i>Built with React, Vite, Node.js, and OpenAI</i>
  <br><br>
  <a href="https://flourishing-sprite-c819cb.netlify.app/"><img src="https://img.shields.io/badge/Live%20Demo-Online-brightgreen?style=for-the-badge" alt="Live Demo"></a>
  <a href="https://github.com/mannino49/Misophonia-companion-v2"><img src="https://img.shields.io/github/stars/mannino49/Misophonia-companion-v2?style=for-the-badge" alt="GitHub Stars"></a>
</p>

---

## üöÄ Features

- **Conversational AI Chatbot:** Powered by OpenAI, get real-time support and information.
- **Soundscape Player:** Customizable soundscapes to help manage triggers.
- **Modern UI:** Responsive, accessible, and visually appealing interface.
- **Progressive Web App:** Installable and works offline.
- **Secure Backend:** All API keys and secrets are kept on the server, never exposed to the client.

---

## üñ•Ô∏è Tech Stack

<div align="center">
  <img src="https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB" />
  <img src="https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=FFD62E" />
  <img src="https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white" />
  <img src="https://img.shields.io/badge/Express-000000?style=for-the-badge&logo=express&logoColor=white" />
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" />
  <img src="https://img.shields.io/badge/Netlify-00C7B7?style=for-the-badge&logo=netlify&logoColor=white" />
</div>

---

## üì¶ Project Structure

```shell
Misophonia Guide/
‚îú‚îÄ‚îÄ public/                # Static assets (icons, manifest)
‚îú‚îÄ‚îÄ src/                   # React frontend source
‚îÇ   ‚îú‚îÄ‚îÄ App.jsx            # Main app logic
‚îÇ   ‚îú‚îÄ‚îÄ main.jsx           # React entry point
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ server/                # Node.js/Express backend
‚îÇ   ‚îú‚îÄ‚îÄ index.js           # API server entry
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ netlify.toml           # Netlify deployment config
‚îú‚îÄ‚îÄ package.json           # Frontend config
‚îî‚îÄ‚îÄ ...
```

---

## ‚ö° Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/g-troiani/misophonia-companion-v3
cd Misophonia-companion-v3
```

### 2. Install dependencies
```bash
npm install
cd server && npm install
```

### 3. Set up environment variables
- Copy `.env.example` to `.env` in the `server/` directory and add your OpenAI API key:
```
OPENAI_API_KEY=your_openai_key_here
```

### 4. Run the backend server
```bash
cd server
npm start
```

### 5. Run the frontend (in a new terminal)
```bash
npm run dev
```

- Frontend: [http://localhost:5173](http://localhost:5173)
- Backend API: [http://localhost:3001](http://localhost:3001)

---

## üåê Deployment

- Deployed on Netlify: [Live Demo](https://flourishing-sprite-c819cb.netlify.app/)
- Backend runs as a separate Node.js server (see `server/`)
- All secrets are stored in environment variables and never exposed to the frontend.

---

## üõ°Ô∏è Security & Best Practices

- **No secrets or API keys are stored in the frontend.**
- **.env files and private keys are gitignored.**
- **Backend validates API key presence and never exposes it to the client.**

---

## ü§ù Contributing

Contributions are welcome! Please open issues or submit pull requests.

---

## üìÑ License

MIT License. See [LICENSE](LICENSE) for details.

---

<p align="center">
  <b>Made with ‚ù§Ô∏è by Mannino49</b>
</p>


================================================================================


################################################################################
# File: scripts/ingest.js
################################################################################

import fs from 'fs';
import path from 'path';
import pdfjsLib from 'pdfjs-dist/legacy/build/pdf.js';
const { getDocument } = pdfjsLib;
import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';

// Load environment variables (make sure FIREBASE_* vars are set in server/.env)
dotenv.config({ path: path.resolve(process.cwd(), 'server/.env') });

// Initialize Supabase
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

// Function to chunk text
function chunkText(text, size = 1000, overlap = 200) {
  const chunks = [];
  for (let start = 0; start < text.length; start += size - overlap) {
    const chunk = text.slice(start, start + size);
    chunks.push(chunk.trim());
  }
  return chunks;
}

async function processPdf(filePath) {
  const buffer = fs.readFileSync(filePath);
  const loadingTask = getDocument({ data: buffer });
  const pdfDoc = await loadingTask.promise;
  const numPages = pdfDoc.numPages;
  let text = '';
  for (let i = 1; i <= numPages; i++) {
    const page = await pdfDoc.getPage(i);
    const content = await page.getTextContent();
    const strings = content.items.map(item => item.str);
    text += strings.join(' ') + '\n';
  }
  const chunks = chunkText(text);
  const basename = path.basename(filePath, '.pdf');
  
  // Prepare chunks for insertion
  const chunksToInsert = chunks.map((chunk, idx) => ({
    file: basename,
    chunk_index: idx,
    text: chunk,
    created_at: new Date()
  }));
  
  // Insert in batches of 500
  const BATCH_SIZE = 500;
  for (let i = 0; i < chunksToInsert.length; i += BATCH_SIZE) {
    const batch = chunksToInsert.slice(i, i + BATCH_SIZE);
    const { error } = await supabase
      .from('research_chunks')
      .insert(batch);
    
    if (error) {
      console.error('Error inserting batch:', error);
      throw error;
    }
  }
  
  console.log(`Indexed ${chunks.length} chunks for ${basename}`);
}

async function main() {
  const dir = path.resolve(process.cwd(), 'documents/research/Global');
  const files = fs.readdirSync(dir).filter(f => f.toLowerCase().endsWith('.pdf'));
  for (const file of files) {
    console.log(`Processing ${file}...`);
    await processPdf(path.join(dir, file));
  }
  console.log('Ingestion complete.');
}

main().catch(err => {
  console.error(err);
  process.exit(1);
});


================================================================================


################################################################################
# File: netlify/functions/chat.js
################################################################################

// File: netlify/functions/chat.js

/**
 * Generic OpenAI chat endpoint
 * POST /.netlify/functions/chat
 * Body: { messages: [ { role:"user"|"assistant"|"system", content:"‚Ä¶" }, ‚Ä¶ ] }
 */
import 'dotenv/config';
import { OpenAI } from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function handler(event /* , context */) {
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ guard HTTP method ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  if (event.httpMethod !== 'POST') {
    return { statusCode: 405, body: 'Method Not Allowed' };
  }

  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ parse body ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  let body;
  try {
    body = JSON.parse(event.body ?? '{}');
  } catch {
    return { statusCode: 400, body: JSON.stringify({ error: 'Invalid JSON' }) };
  }

  const { messages } = body;
  if (!Array.isArray(messages) || messages.length === 0) {
    return {
      statusCode: 400,
      body: JSON.stringify({ error: 'messages array required' }),
    };
  }

  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OpenAI call ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages,
      max_tokens: 512,
      temperature: 0.7,
    });

    const reply =
      completion.choices?.[0]?.message?.content ?? '‚ö†Ô∏è no response';

    return {
      statusCode: 200,
      headers: { 'content-type': 'application/json' },
      body: JSON.stringify({ reply }),
    };
  } catch (err) {
    console.error('OpenAI error ‚Üí', err);
    return {
      statusCode: 500,
      headers: { 'content-type': 'application/json' },
      body: JSON.stringify({ error: 'Error from OpenAI API' }),
    };
  }
}


================================================================================


################################################################################
# File: eslint.config.js
################################################################################

import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...reactHooks.configs.recommended.rules,
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]


================================================================================


################################################################################
# File: requirements.txt
################################################################################

################################################################################
################################################################################
# Python dependencies for Misophonia Research RAG System

# Core dependencies
firebase-admin>=6.2.0
openai>=1.0.0
numpy>=1.24.0
python-dotenv>=1.0.0
flask>=2.0.0
requests>=2.28.0

# PDF processing
PyPDF2>=3.0.0
unstructured>=0.10.0
pdfminer.six>=20221105

# Utilities
tqdm>=4.65.0
tabulate>=0.9.0
colorama>=0.4.6
argparse>=1.4.0

# Firebase/Google Cloud
google-cloud-firestore>=2.11.0

# For concurrent processing
concurrent-log-handler>=0.9.20

# Supabase integration
supabase~=2.0.0


================================================================================


################################################################################
# File: netlify/functions/_utils.js
################################################################################

// Shared constants for Netlify functions

// Which LLM powers the Research Assistant ("openai" | "gemini") ‚Äì defaults to "openai"
export const AI_PROVIDER = process.env.AI_PROVIDER || 'openai';

// Location of the running RAG service (rag_web_app_v9.py)
// Hard-wire the production URL so the function works even
// when the env var is missing.
export const RAG_HOST =
  process.env.RAG_HOST || 'https://misophonia-rag.fly.dev';   // ‚Üê your URL


================================================================================

